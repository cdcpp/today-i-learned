# 2025-07-13 TIL

## 오늘 한 일

-   김영한님의 '스프링 입문' 강의 완강(복습)
-   강의 완강을 기념하여, 그동안 구상했던 개인 프로젝트의 핵심 기능에 대한 설계를 시작했다.

---

## 주제: 키워드 확장 기능 설계를 위한 기술 비교 분석 (API vs. 웹 크롤링)

### 설계 목표
개인 프로젝트 '티스토리 자동화 시스템'의 핵심 기능 중 하나로, '영양제'와 같은 상위 키워드가 주어졌을 때, '오메가3', '마그네슘' 등 연관된 하위 키워드 목록을 자동으로 수집하여 데이터베이스에 저장하는 기능을 구현하고자 한다.

### 기술적 접근법 비교

이 목표를 달성하기 위한 두 가지 주요 기술의 장단점을 분석했다.

#### 1. 외부 API 활용 (네이버/구글 광고 API)

-   **장점:**
    -   **데이터 신뢰성:** 실제 사용자 검색 데이터를 기반으로 하므로, 연관 키워드의 정확도와 질이 매우 높다.
    -   **안정성:** 공식적으로 제공되는 API이므로, 상대방의 정책 변경이나 차단에 대한 걱정 없이 안정적인 데이터 수집이 가능하다.
    -   **부가 데이터:** 월간 검색량, 경쟁 강도 등 SEO에 유용한 추가 데이터까지 확보할 수 있다.
-   **단점:**
    -   **복잡한 절차:** API 사용을 위한 개발자 등록, 애플리케이션 심사, 승인 등의 절차가 필요하다.
    * **비용 발생 가능성:** API 호출량에 따라 비용이 발생할 수 있다.

#### 2. 웹 크롤링 (Selenium)

-   **장점:**
    -   **개발 즉시성:** 별도의 승인 절차 없이, 즉시 개발에 착수할 수 있다.
    -   **비용 효율성:** 초기 개발 비용이 없다.
-   **단점:**
    -   **불안정성 (치명적):** 크롤링 대상 사이트(네이버 등)의 HTML 구조가 조금만 변경되어도 크롤러가 바로 작동을 멈춘다. 지속적인 유지보수가 필수적이다.
    -   **견고함 부족:** IP 차단 등 비정상적인 접근으로 인식될 위험이 존재한다.

### 고민 및 다음 단계
이전 스타트업에서 삭제 자동화를 구현했던 Selenium을 사용하면 구현하는데 시간이 조금 더 걸릴 것 같고... HTML이 변하면 코드를 수정해야한다.
API를 이용하여 키워드를 "저장" 하는게 맞다고 생각하는데... 하루이틀정도는 고민이 필요한 것 같다...
내일부터는 스프링 인강을 들을 예정이다 힘내자!!
